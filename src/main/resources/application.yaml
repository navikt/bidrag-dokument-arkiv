server:
  servlet:
    context-path: /bidrag-dokument-arkiv
management:
  endpoints:
    web:
      exposure:
        include: "prometheus,health"
springdoc:
  packages-to-scan: no.nav.bidrag.dokument.arkiv.controller

STS_ISSUER_URL: ${STS_ISSUER_URL:${ACCESS_TOKEN_URL}}
---

spring.profiles: live

# OIDC
no.nav.security.jwt:
  issuer:
    isso:
      acceptedaudience: ${ACCEPTED_AUDIENCE}
      discoveryurl: ${ISSO_ISSUER_URL}/.well-known/openid-configuration
    sts:
      accepted_audience: ${ACCEPTED_SERVICE_USER_AUDIENCE}
      discoveryurl: ${STS_ISSUER_URL}/rest/v1/sts/.well-known/openid-configuration


spring.kafka:
    bootstrap-servers: ${KAFKA_BROKERS}
    properties:
      security.protocol: SSL
      specific.avro.reader: true
      schema.registry.url: ${KAFKA_SCHEMA_REGISTRY}
      basic.auth.credentials.source: USER_INFO
      basic.auth.user.info: ${KAFKA_SCHEMA_REGISTRY_USER}:${KAFKA_SCHEMA_REGISTRY_PASSWORD}
      ssl:
        keystore:
          type: PKCS12
          location: ${KAFKA_KEYSTORE_PATH}
          password: ${KAFKA_CREDSTORE_PASSWORD}
        truststore:
          location: ${KAFKA_TRUSTSTORE_PATH}
          password: ${KAFKA_CREDSTORE_PASSWORD}
    consumer:
      group-id: ${NAIS_APP_NAME}
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
      properties:
        spring.deserializer.value.delegate.class: io.confluent.kafka.serializers.KafkaAvroDeserializer
        max.poll.interval.ms: 50000
        retry.backoff.ms: 5000
        reconnect.backoff.ms: 8000
      enableAutoCommit: false
    listener:
      ackMode: RECORD
